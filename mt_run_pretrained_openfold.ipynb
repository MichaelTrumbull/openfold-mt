{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step run of run_pretrained_openfold.py\n",
    "investigating new conformations in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from openfold.utils.script_utils import load_models_from_command_line, parse_fasta, run_model, prep_output, \\\n",
    "    update_timings, relax_protein\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__file__)\n",
    "logger.setLevel(level=logging.INFO)\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "torch_versions = torch.__version__.split(\".\")\n",
    "torch_major_version = int(torch_versions[0])\n",
    "torch_minor_version = int(torch_versions[1])\n",
    "if(\n",
    "    torch_major_version > 1 or \n",
    "    (torch_major_version == 1 and torch_minor_version >= 12)\n",
    "):\n",
    "    # Gives a large speedup on Ampere-class GPUs\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from openfold.config import model_config\n",
    "from openfold.data import templates, feature_pipeline, data_pipeline\n",
    "from openfold.np import residue_constants, protein\n",
    "import openfold.np.relax.relax as relax\n",
    "\n",
    "from openfold.utils.tensor_utils import (\n",
    "    tensor_tree_map,\n",
    ")\n",
    "from openfold.utils.trace_utils import (\n",
    "    pad_feature_dict_seq,\n",
    "    trace_model_,\n",
    ")\n",
    "from scripts.utils import add_data_args\n",
    "\n",
    "\n",
    "TRACING_INTERVAL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "def precompute_alignments(tags, seqs, alignment_dir, args):\n",
    "    for tag, seq in zip(tags, seqs):\n",
    "        tmp_fasta_path = os.path.join(args.output_dir, f\"tmp_{os.getpid()}.fasta\")\n",
    "        with open(tmp_fasta_path, \"w\") as fp:\n",
    "            fp.write(f\">{tag}\\n{seq}\")\n",
    "\n",
    "        local_alignment_dir = os.path.join(alignment_dir, tag)\n",
    "        if(args.use_precomputed_alignments is None and not os.path.isdir(local_alignment_dir)):\n",
    "            logger.info(f\"Generating alignments for {tag}...\")\n",
    "                \n",
    "            os.makedirs(local_alignment_dir)\n",
    "\n",
    "            alignment_runner = data_pipeline.AlignmentRunner(\n",
    "                jackhmmer_binary_path=args.jackhmmer_binary_path,\n",
    "                hhblits_binary_path=args.hhblits_binary_path,\n",
    "                hhsearch_binary_path=args.hhsearch_binary_path,\n",
    "                uniref90_database_path=args.uniref90_database_path,\n",
    "                mgnify_database_path=args.mgnify_database_path,\n",
    "                bfd_database_path=args.bfd_database_path,\n",
    "                uniclust30_database_path=args.uniclust30_database_path,\n",
    "                pdb70_database_path=args.pdb70_database_path,\n",
    "                no_cpus=args.cpus,\n",
    "            )\n",
    "            alignment_runner.run(\n",
    "                tmp_fasta_path, local_alignment_dir\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\n",
    "                f\"Using precomputed alignments for {tag} at {alignment_dir}...\"\n",
    "            )\n",
    "\n",
    "        # Remove temporary FASTA file\n",
    "        os.remove(tmp_fasta_path)\n",
    "\n",
    "\n",
    "def round_up_seqlen(seqlen):\n",
    "    return int(math.ceil(seqlen / TRACING_INTERVAL)) * TRACING_INTERVAL\n",
    "\n",
    "\n",
    "def generate_feature_dict(\n",
    "    tags,\n",
    "    seqs,\n",
    "    alignment_dir,\n",
    "    data_processor,\n",
    "    args,\n",
    "):\n",
    "    tmp_fasta_path = os.path.join(args.output_dir, f\"tmp_{os.getpid()}.fasta\")\n",
    "    if len(seqs) == 1:\n",
    "        tag = tags[0]\n",
    "        seq = seqs[0]\n",
    "        with open(tmp_fasta_path, \"w\") as fp:\n",
    "            fp.write(f\">{tag}\\n{seq}\")\n",
    "\n",
    "        local_alignment_dir = os.path.join(alignment_dir, tag)\n",
    "        feature_dict = data_processor.process_fasta(\n",
    "            fasta_path=tmp_fasta_path, alignment_dir=local_alignment_dir\n",
    "        )\n",
    "    else:\n",
    "        with open(tmp_fasta_path, \"w\") as fp:\n",
    "            fp.write(\n",
    "                '\\n'.join([f\">{tag}\\n{seq}\" for tag, seq in zip(tags, seqs)])\n",
    "            )\n",
    "        feature_dict = data_processor.process_multiseq_fasta(\n",
    "            fasta_path=tmp_fasta_path, super_alignment_dir=alignment_dir,\n",
    "        )\n",
    "\n",
    "    # Remove temporary FASTA file\n",
    "    os.remove(tmp_fasta_path)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "def list_files_with_extensions(dir, extensions):\n",
    "    return [f for f in os.listdir(dir) if f.endswith(extensions)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argparser emulation\n",
    "class pseudo_parser:\n",
    "    \n",
    "self.fasta_dir\n",
    "parser.add_argument(\n",
    "    \"fasta_dir\", type=str,\n",
    "    help=\"Path to directory containing FASTA files, one sequence per file\"\n",
    ")\n",
    "self.template_mmcif_dir\n",
    "parser.add_argument(\n",
    "    \"template_mmcif_dir\", type=str,\n",
    ")\n",
    "self.use_precomputed_alignments\n",
    "parser.add_argument(\n",
    "    \"--use_precomputed_alignments\", type=str, default=None,\n",
    "    help=\"\"\"Path to alignment directory. If provided, alignment computation \n",
    "            is skipped and database path arguments are ignored.\"\"\"\n",
    ")\n",
    "self.output_dir\n",
    "parser.add_argument(\n",
    "    \"--output_dir\", type=str, default=os.getcwd(),\n",
    "    help=\"\"\"Name of the directory in which to output the prediction\"\"\",\n",
    ")\n",
    "self.model_device\n",
    "parser.add_argument(\n",
    "    \"--model_device\", type=str, default=\"cpu\",\n",
    "    help=\"\"\"Name of the device on which to run the model. Any valid torch\n",
    "            device name is accepted (e.g. \"cpu\", \"cuda:0\")\"\"\"\n",
    ")\n",
    "self.config_preset\n",
    "parser.add_argument(\n",
    "    \"--config_preset\", type=str, default=\"model_1\",\n",
    "    help=\"\"\"Name of a model config preset defined in openfold/config.py\"\"\"\n",
    ")\n",
    "self.jax_param_path\n",
    "parser.add_argument(\n",
    "    \"--jax_param_path\", type=str, default=None,\n",
    "    help=\"\"\"Path to JAX model parameters. If None, and openfold_checkpoint_path\n",
    "            is also None, parameters are selected automatically according to \n",
    "            the model name from openfold/resources/params\"\"\"\n",
    ")\n",
    "self.openfold_checkpoint_path\n",
    "parser.add_argument(\n",
    "    \"--openfold_checkpoint_path\", type=str, default=None,\n",
    "    help=\"\"\"Path to OpenFold checkpoint. Can be either a DeepSpeed \n",
    "            checkpoint directory or a .pt file\"\"\"\n",
    ")\n",
    "self.save_outputs\n",
    "parser.add_argument(\n",
    "    \"--save_outputs\", action=\"store_true\", default=False,\n",
    "    help=\"Whether to save all model outputs, including embeddings, etc.\"\n",
    ")\n",
    "self.cpus\n",
    "parser.add_argument(\n",
    "    \"--cpus\", type=int, default=4,\n",
    "    help=\"\"\"Number of CPUs with which to run alignment tools\"\"\"\n",
    ")\n",
    "self.preset\n",
    "parser.add_argument(\n",
    "    \"--preset\", type=str, default='full_dbs',\n",
    "    choices=('reduced_dbs', 'full_dbs')\n",
    ")\n",
    "self.output_postfix\n",
    "parser.add_argument(\n",
    "    \"--output_postfix\", type=str, default=None,\n",
    "    help=\"\"\"Postfix for output prediction filenames\"\"\"\n",
    ")\n",
    "self.data_random_seed\n",
    "parser.add_argument(\n",
    "    \"--data_random_seed\", type=str, default=None\n",
    ")\n",
    "self.skip_relaxation\n",
    "parser.add_argument(\n",
    "    \"--skip_relaxation\", action=\"store_true\", default=False,\n",
    ")\n",
    "self.multimer_ri_gap\n",
    "parser.add_argument(\n",
    "    \"--multimer_ri_gap\", type=int, default=200,\n",
    "    help=\"\"\"Residue index offset between multiple sequences, if provided\"\"\"\n",
    ")\n",
    "self.trace_model\n",
    "parser.add_argument(\n",
    "    \"--trace_model\", action=\"store_true\", default=False,\n",
    "    help=\"\"\"Whether to convert parts of each model to TorchScript.\n",
    "            Significantly improves runtime at the cost of lengthy\n",
    "            'compilation.' Useful for large batch jobs.\"\"\"\n",
    ")\n",
    "self.subtract_plddt\n",
    "parser.add_argument(\n",
    "    \"--subtract_plddt\", action=\"store_true\", default=False,\n",
    "    help=\"\"\"\"Whether to output (100 - pLDDT) in the B-factor column instead\n",
    "                of the pLDDT itself\"\"\"\n",
    ")\n",
    "self.p = True\n",
    "parser.add_argument(\n",
    "    '-p', action='store_true', default=False,\n",
    "    help=\"\"\"Trigger print statements during runtime. Print statements \n",
    "    describe each step in the process\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "self.uniref90_database_path\n",
    "parser.add_argument(\n",
    "    '--uniref90_database_path', type=str, default=None,\n",
    ")\n",
    "self.mgnify_database_path\n",
    "parser.add_argument(\n",
    "    '--mgnify_database_path', type=str, default=None,\n",
    ")\n",
    "self.pdb70_database_path\n",
    "parser.add_argument(\n",
    "    '--pdb70_database_path', type=str, default=None,\n",
    ")\n",
    "self.uniclust30_database_path\n",
    "parser.add_argument(\n",
    "    '--uniclust30_database_path', type=str, default=None,\n",
    ")\n",
    "self.bfd_database_path\n",
    "parser.add_argument(\n",
    "    '--bfd_database_path', type=str, default=None,\n",
    ")\n",
    "self.jackhmmer_binary_path\n",
    "parser.add_argument(\n",
    "    '--jackhmmer_binary_path', type=str, default='/usr/bin/jackhmmer'\n",
    ")\n",
    "self.hhblits_binary_path\n",
    "parser.add_argument(\n",
    "    '--hhblits_binary_path', type=str, default='/usr/bin/hhblits'\n",
    ")\n",
    "self.hhsearch_binary_path\n",
    "parser.add_argument(\n",
    "    '--hhsearch_binary_path', type=str, default='/usr/bin/hhsearch'\n",
    ")\n",
    "self.kalign_binary_path\n",
    "parser.add_argument(\n",
    "    '--kalign_binary_path', type=str, default='/usr/bin/kalign'\n",
    ")\n",
    "self.max_template_date\n",
    "parser.add_argument(\n",
    "    '--max_template_date', type=str,\n",
    "    default=date.today().strftime(\"%Y-%m-%d\"),\n",
    ")\n",
    "self.obsolete_pdbs_path\n",
    "parser.add_argument(\n",
    "    '--obsolete_pdbs_path', type=str, default=None\n",
    ")\n",
    "self.release_dates_path\n",
    "parser.add_argument(\n",
    "    '--release_dates_path', type=str, default=None\n",
    ")\n",
    "\n",
    "args = pseudo_parser()\n",
    "\n",
    "if(args.jax_param_path is None and args.openfold_checkpoint_path is None):\n",
    "    args.jax_param_path = os.path.join(\n",
    "        \"openfold\", \"resources\", \"params\", \n",
    "        \"params_\" + args.config_preset + \".npz\"\n",
    "    )\n",
    "\n",
    "if(args.model_device == \"cpu\" and torch.cuda.is_available()):\n",
    "    logging.warning(\n",
    "        \"\"\"The model is being run on CPU. Consider specifying \n",
    "        --model_device for better performance\"\"\"\n",
    "    )\n",
    "\n",
    "#main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.template_mmcif_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
